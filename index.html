<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Zilyu Ye&#39;s Homepage</title>
    <meta name="description" content="The description of the site.">
    <link rel="icon" href="/logo.png">
    
    <link rel="preload" href="/assets/css/0.styles.65e01003.css" as="style"><link rel="preload" href="/assets/js/app.2aa8338d.js" as="script"><link rel="preload" href="/assets/js/2.b38bef16.js" as="script"><link rel="preload" href="/assets/js/7.cb8b0411.js" as="script"><link rel="preload" href="/assets/js/4.dab95bb3.js" as="script"><link rel="preload" href="/assets/js/5.bd97189a.js" as="script"><link rel="prefetch" href="/assets/js/10.5a56c157.js"><link rel="prefetch" href="/assets/js/11.558ce76f.js"><link rel="prefetch" href="/assets/js/12.ad1820cf.js"><link rel="prefetch" href="/assets/js/13.361c374b.js"><link rel="prefetch" href="/assets/js/14.02be7e5f.js"><link rel="prefetch" href="/assets/js/15.983dbc07.js"><link rel="prefetch" href="/assets/js/16.cf9fee51.js"><link rel="prefetch" href="/assets/js/3.82f374f2.js"><link rel="prefetch" href="/assets/js/6.67793f9c.js"><link rel="prefetch" href="/assets/js/8.be611428.js"><link rel="prefetch" href="/assets/js/9.d19f5bf3.js">
    <link rel="stylesheet" href="/assets/css/0.styles.65e01003.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar home-page"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-exact-active router-link-active"><!----> <span class="site-name">Zilyu Ye's Homepage</span></a> <div class="links"><!----> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link router-link-exact-active router-link-active">Home</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link router-link-exact-active router-link-active">Home</a></div> <!----></nav>  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><div class="profile"><div class="image"><img src="/profile.jpg" alt></div> <div class="info"><div class="name">
      Zilyu Ye
    </div> <div class="bio"><p>Student majoring in Artificial Intelligence at South China University of Technology</p></div> <div class="socials"><div><a href="https://github.com/YeLuoSuiYou" target="_blank"><img src="/icons/github.svg" alt="github" title="github"></a></div></div> <div class="contact"><div title="Contact me" class="email">zilyuye@foxmail.com</div></div> <div><a target="_blank" href="/cv.pdf" title="Download my CV in PDF"><font size="2em" color=""><b>[CV]</b></font></a></div></div></div> <h2 id="about-me">About Me</h2> <p>Hi, I'm Zilyu, a second-year undergraduate student majoring in Artificial Intelligence at South China University of Technology. I'm currently working on my research project on AIGC supervised by <a href="https://drliuqi.github.io/" target="_blank" rel="noopener noreferrer">Prof. Qi Liu<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> and <a href="http://maple-lab.net/about.html" target="_blank" rel="noopener noreferrer">Prof. Guo-Jun Qi<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>.</p> <p><span style="color:red;">Sincerely looking for Ph.D. positions for fall 2026 and internships opportunities in for Summer 2024.</span></p> <h3 id="research-interests">Research Interests</h3> <p>Computer Vision, Multimodal Learning, AIGC, Diffusion Model etc.</p> <h2 id="news">News</h2> <ul><li>[March 2024] Submit a paper focusing on the open-domain visual storytelling task to CVPR 2024 workshop.</li></ul> <h2 id="education-experiences">Education &amp; Experiences</h2> <ul><li><strong>South China University of Technology (SCUT)</strong><br>
Undergraduate major in Artificial Intelligence, 2022.9 - 2026.6 (expected)<br></li> <li><strong>Multimodal Computing and Emotional Interaction Lab in SCUT</strong><br>
Research intern on AIGC supervised by <a href="https://drliuqi.github.io/" target="_blank" rel="noopener noreferrer">Prof. Qi Liu<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>, 2023.11 - present<br></li> <li><strong>Machine Perception and Learning (MAPLE) Lab in Westlake University</strong><br>
Research intern on AIGC supervised by <a href="http://maple-lab.net/about.html" target="_blank" rel="noopener noreferrer">Prof. Guo-Jun Qi<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>, 2024.3 - present<br></li> <li><strong>Undergraduate Student Robotic Lab (ROBOTIC) in SCUT</strong><br>
Member of machine vision team participating in ROBOCON competition, 2022.12 - 2023.6<br></li></ul> <h2 id="papers-and-projects">Papers and Projects</h2> <div class="md-card"><div class="card-image"><img src="/projects/OpenStory.png" alt></div> <div class="card-content"><p><span style="font-size:1.1em;"><strong>OpenStory: A Large-Scale Open-Domain Dataset for Subject-Driven Visual Storytelling</strong></span></p> <p>Zilyu Ye*, Jinxiu Liu*, Jinjin Cao, Zhiyang Chen, Ziwei Xuan, Mingyuan Zhou, Qi Liu, Guo-Jun Qi</p> <p>Recently, the advancement and evolution of genera-tive AI have been highly compelling. In this paper, wepresent OpenStory, a large-scale dataset tailored for train-ing subject-focused story visualization models to generatecoherent and contextually relevant visual narratives. Ad-dressing the challenges of maintaining subject continuityacross frames and capturing compelling narratives, We propose an innovative pipeline that automates the extraction ofkeyframes from open-domain videos. It ingeniously employsvision-language models to generate descriptive captions,which are then refined by a large language model to ensurenarrative flow and coherence. Furthermore, advanced sub-ject masking techniques are applied to isolate and segmentthe primary subjects. Derived from diverse video sources,including YouTube and existing datasets, OpenStory offersa comprehensive open-domain resource, surpassing priordatasets confined to specific scenarios. With automatedcaptioning instead of manual annotation, high-resolutionimagery optimized for subject count per frame, and exten-sive frame sequences ensuring consistent subjects for tem-poral modeling, OpenStory establishes itself as an invalu-able benchmark. It facilitates advancements in subject-focused story visualization, enabling the training of modelscapable of comprehending and generating intricate multi-modal narratives from extensive visual and textual inputs.</p> <p>CVPR 2024 workshop, under review</p></div></div> <h2 id="awards-honors">Awards &amp; Honors</h2> <ul><li>SCUT undergraduate scholoarship, 2022 -- Third Prize</li> <li>Excellent Group Enterprise Scholarship, SCUT, 2023 -- Third Prize</li> <li>Asia and Pacific Mathematical Modeling Contest —Third Prize</li> <li>National College Student Robot Contest (ROBOCON) —Third Prize</li> <li>National Undergraduate Mathematical Modeling Contest In Guangdong Province — Second Prize</li> <li>SCUT Future Technology Institute &quot;Alibaba Cloud Cup&quot; Programming Competition — Third Prize</li></ul></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated:</span> <span class="time">4/7/2024, 2:35:57 PM</span></div></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.2aa8338d.js" defer></script><script src="/assets/js/2.b38bef16.js" defer></script><script src="/assets/js/7.cb8b0411.js" defer></script><script src="/assets/js/4.dab95bb3.js" defer></script><script src="/assets/js/5.bd97189a.js" defer></script>
  </body>
</html>
